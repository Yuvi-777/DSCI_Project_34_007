{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d12961f8",
   "metadata": {},
   "source": [
    "# Group Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b6e3a4",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a37646",
   "metadata": {},
   "source": [
    "Heart disease is increasingly common and one of the leading causes of death around the world. As algorithms and modeling become more accessible and sophisticated, they can be used to predict and diagnose heart disease. Here, we will create a simple model using the k-nearest neighbors algorithm to predict whether the patient has the symptoms of chest pain in individuals testing for heart disease. We will investigate how accurately we can predict the occurrence of chest pain with a K-nearest Neighbor model? \n",
    "\n",
    "The dataset we will use is called “processed.cleveland.data” from the Machine Learning Repository. Data was collected between May 1981 and September 1984 and stems from the angiography results of 303 patients at the Cleveland Clinic in Cleveland, Ohio. The average age of study participants was 54 and 206 of the 303 participants were men (“International application of a new probability algorithm”). Similar algorithms have been created like the one described in Detrano et al.’s International Application of a New Probability Algorithm for the Diagnosis of Coronary Artery Disease where the same data set, along with similar ones, trained an algorithm to predict heart disease. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08364a0a",
   "metadata": {},
   "source": [
    "## Methods and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f4c641",
   "metadata": {},
   "source": [
    "As mentioned previously, we will develop a model using this dataset to predict the patient’s chance of experiencing chest pain. The potential types of chest pain are typical angina, atypical angina, non-anginal pain, and asymptomatic pain. Our model will use the k-nearest neighbors algorithm and consider age, sex, electrocardiogram rate at rest (restecg), systolic blood pressure (trestbps), and cholesterol (chol) as variables. Age and sex were chosen because women report a greater risk of developing CVD than men of the same age group; however, the risk of developing CVD increases with age in both sexes (Rodgers et al., 2019). The American Heart Association reported that in the US, the likelihood of developing CVD for men and women between the ages of 40-59 is ~40%, between 60-79 years is ~75%, and above the age of 80, the likelihood increased to ~86%. By incorporating age and sex, we can better estimate an individual’s likelihood of developing CVD (Rodgers et al., 2019). The electrocardiogram at rest provides information about heart rate, rhythm, and potential heart enlargement, making it a useful tool for investigating symptoms (Electrocardiogram, 2023). The heart's activity is measured by electrical activity and the electrical impulse that travels through your heart (Electrocardiogram, 2023). The electrical passage can be tracked and used to determine whether the activity is regular or irregular. ECG is often used when experiencing chest pains, and the result can be correlated with numerous heart conditions (Electrocardiogram, 2023). Another factor we selected is blood pressure (BP). BP is one of the most important risk factors for CVD and the leading cause of mortality (Wu et al., 2015). Heart disease is associated with elevated systolic blood pressure, which damages arteries and impedes blood flow to the heart muscle. It is estimated that BP will affect 65% of the population for individuals over the age of 60 (Wu et al., 2015). Additionally, abnormal levels of serum cholesterol in the blood increase the risk of heart disease by promoting the development of fatty deposits in blood vessels, which can hinder flow through arteries (Carson, 2023). Although studies conducted do not indicate a strong association with CVD risk, it is still included as a variable due to the relationship of dietary cholesterol with heart health (Carson, 2023).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc476272",
   "metadata": {},
   "source": [
    "Let's load the important --- and set a seed so that the project is reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85edcf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.6     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.7     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.9\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.2     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 1.0.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mrsample     \u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials       \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mtune        \u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer       \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mworkflows   \u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip     \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34myardstick   \u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mrecipes     \u001b[39m 1.0.1     \n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\u001b[34m•\u001b[39m Use \u001b[32mtidymodels_prefer()\u001b[39m to resolve common conflicts.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(tidymodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aecd65",
   "metadata": {},
   "source": [
    "We need to first read the dataset from the internet. After reading the data, we can rename the columns to make the data more informative. This is done below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f20c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m303\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m14\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m  (2): X12, X13\n",
      "\u001b[32mdbl\u001b[39m (12): X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X14\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\"\n",
    "cleveland_data <- read_csv(url, col_names = FALSE)\n",
    "cleveland_data <- rename(cleveland_data,\n",
    "       age = X1, \n",
    "       sex = X2, \n",
    "       cp = X3,\n",
    "       trestbps = X4, \n",
    "       chol = X5, \n",
    "       fbs = X6, \n",
    "       restecg = X7, \n",
    "       thalach = X8, \n",
    "       exang = X9, \n",
    "       oldpeak = X10, \n",
    "       slope = X11, \n",
    "       ca = X12, \n",
    "       thal = X13, \n",
    "       num = X14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190c55a1",
   "metadata": {},
   "source": [
    "The data is then mutated to convert the columns into the right variable type. For example, since cp(chest pain) is a factor, we can use the as_factor function to convert the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b87e7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cd_mutate <- cleveland_data |>\n",
    "mutate(cp = as_factor(cp)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5141540d",
   "metadata": {},
   "source": [
    "The dataset for heart disease contains \"?\" instead of NA values which might be difficult to deal with later on. We can replace all the \"?\" to NA as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "010f374e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 299 × 14</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>age</th><th scope=col>sex</th><th scope=col>cp</th><th scope=col>trestbps</th><th scope=col>chol</th><th scope=col>fbs</th><th scope=col>restecg</th><th scope=col>thalach</th><th scope=col>exang</th><th scope=col>oldpeak</th><th scope=col>slope</th><th scope=col>ca</th><th scope=col>thal</th><th scope=col>num</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>63</td><td>1</td><td>1</td><td>145</td><td>233</td><td>1</td><td>2</td><td>150</td><td>0</td><td>2.3</td><td>3</td><td>0.0</td><td>6.0</td><td>0</td></tr>\n",
       "\t<tr><td>67</td><td>1</td><td>0</td><td>160</td><td>286</td><td>0</td><td>2</td><td>108</td><td>1</td><td>1.5</td><td>2</td><td>3.0</td><td>3.0</td><td>2</td></tr>\n",
       "\t<tr><td>67</td><td>1</td><td>0</td><td>120</td><td>229</td><td>0</td><td>2</td><td>129</td><td>1</td><td>2.6</td><td>2</td><td>2.0</td><td>7.0</td><td>1</td></tr>\n",
       "\t<tr><td>37</td><td>1</td><td>1</td><td>130</td><td>250</td><td>0</td><td>0</td><td>187</td><td>0</td><td>3.5</td><td>3</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>41</td><td>0</td><td>1</td><td>130</td><td>204</td><td>0</td><td>2</td><td>172</td><td>0</td><td>1.4</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>56</td><td>1</td><td>1</td><td>120</td><td>236</td><td>0</td><td>0</td><td>178</td><td>0</td><td>0.8</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>62</td><td>0</td><td>0</td><td>140</td><td>268</td><td>0</td><td>2</td><td>160</td><td>0</td><td>3.6</td><td>3</td><td>2.0</td><td>3.0</td><td>3</td></tr>\n",
       "\t<tr><td>57</td><td>0</td><td>0</td><td>120</td><td>354</td><td>0</td><td>0</td><td>163</td><td>1</td><td>0.6</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>63</td><td>1</td><td>0</td><td>130</td><td>254</td><td>0</td><td>2</td><td>147</td><td>0</td><td>1.4</td><td>2</td><td>1.0</td><td>7.0</td><td>2</td></tr>\n",
       "\t<tr><td>53</td><td>1</td><td>0</td><td>140</td><td>203</td><td>1</td><td>2</td><td>155</td><td>1</td><td>3.1</td><td>3</td><td>0.0</td><td>7.0</td><td>1</td></tr>\n",
       "\t<tr><td>57</td><td>1</td><td>0</td><td>140</td><td>192</td><td>0</td><td>0</td><td>148</td><td>0</td><td>0.4</td><td>2</td><td>0.0</td><td>6.0</td><td>0</td></tr>\n",
       "\t<tr><td>56</td><td>0</td><td>1</td><td>140</td><td>294</td><td>0</td><td>2</td><td>153</td><td>0</td><td>1.3</td><td>2</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>56</td><td>1</td><td>1</td><td>130</td><td>256</td><td>1</td><td>2</td><td>142</td><td>1</td><td>0.6</td><td>2</td><td>1.0</td><td>6.0</td><td>2</td></tr>\n",
       "\t<tr><td>44</td><td>1</td><td>1</td><td>120</td><td>263</td><td>0</td><td>0</td><td>173</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>7.0</td><td>0</td></tr>\n",
       "\t<tr><td>52</td><td>1</td><td>1</td><td>172</td><td>199</td><td>1</td><td>0</td><td>162</td><td>0</td><td>0.5</td><td>1</td><td>0.0</td><td>7.0</td><td>0</td></tr>\n",
       "\t<tr><td>57</td><td>1</td><td>1</td><td>150</td><td>168</td><td>0</td><td>0</td><td>174</td><td>0</td><td>1.6</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>48</td><td>1</td><td>1</td><td>110</td><td>229</td><td>0</td><td>0</td><td>168</td><td>0</td><td>1.0</td><td>3</td><td>0.0</td><td>7.0</td><td>1</td></tr>\n",
       "\t<tr><td>54</td><td>1</td><td>0</td><td>140</td><td>239</td><td>0</td><td>0</td><td>160</td><td>0</td><td>1.2</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>48</td><td>0</td><td>1</td><td>130</td><td>275</td><td>0</td><td>0</td><td>139</td><td>0</td><td>0.2</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>49</td><td>1</td><td>1</td><td>130</td><td>266</td><td>0</td><td>0</td><td>171</td><td>0</td><td>0.6</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>64</td><td>1</td><td>1</td><td>110</td><td>211</td><td>0</td><td>2</td><td>144</td><td>1</td><td>1.8</td><td>2</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>58</td><td>0</td><td>1</td><td>150</td><td>283</td><td>1</td><td>2</td><td>162</td><td>0</td><td>1.0</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>58</td><td>1</td><td>1</td><td>120</td><td>284</td><td>0</td><td>2</td><td>160</td><td>0</td><td>1.8</td><td>2</td><td>0.0</td><td>3.0</td><td>1</td></tr>\n",
       "\t<tr><td>58</td><td>1</td><td>1</td><td>132</td><td>224</td><td>0</td><td>2</td><td>173</td><td>0</td><td>3.2</td><td>1</td><td>2.0</td><td>7.0</td><td>3</td></tr>\n",
       "\t<tr><td>60</td><td>1</td><td>0</td><td>130</td><td>206</td><td>0</td><td>2</td><td>132</td><td>1</td><td>2.4</td><td>2</td><td>2.0</td><td>7.0</td><td>4</td></tr>\n",
       "\t<tr><td>50</td><td>0</td><td>1</td><td>120</td><td>219</td><td>0</td><td>0</td><td>158</td><td>0</td><td>1.6</td><td>2</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>58</td><td>0</td><td>1</td><td>120</td><td>340</td><td>0</td><td>0</td><td>172</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>66</td><td>0</td><td>1</td><td>150</td><td>226</td><td>0</td><td>0</td><td>114</td><td>0</td><td>2.6</td><td>3</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>43</td><td>1</td><td>0</td><td>150</td><td>247</td><td>0</td><td>0</td><td>171</td><td>0</td><td>1.5</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>40</td><td>1</td><td>0</td><td>110</td><td>167</td><td>0</td><td>2</td><td>114</td><td>1</td><td>2.0</td><td>2</td><td>0.0</td><td>7.0</td><td>3</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>66</td><td>1</td><td>0</td><td>160</td><td>228</td><td>0</td><td>2</td><td>138</td><td>0</td><td>2.3</td><td>1</td><td>0.0</td><td>6.0</td><td>0</td></tr>\n",
       "\t<tr><td>46</td><td>1</td><td>0</td><td>140</td><td>311</td><td>0</td><td>0</td><td>120</td><td>1</td><td>1.8</td><td>2</td><td>2.0</td><td>7.0</td><td>2</td></tr>\n",
       "\t<tr><td>71</td><td>0</td><td>0</td><td>112</td><td>149</td><td>0</td><td>0</td><td>125</td><td>0</td><td>1.6</td><td>2</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>59</td><td>1</td><td>1</td><td>134</td><td>204</td><td>0</td><td>0</td><td>162</td><td>0</td><td>0.8</td><td>1</td><td>2.0</td><td>3.0</td><td>1</td></tr>\n",
       "\t<tr><td>64</td><td>1</td><td>1</td><td>170</td><td>227</td><td>0</td><td>2</td><td>155</td><td>0</td><td>0.6</td><td>2</td><td>0.0</td><td>7.0</td><td>0</td></tr>\n",
       "\t<tr><td>66</td><td>0</td><td>1</td><td>146</td><td>278</td><td>0</td><td>2</td><td>152</td><td>0</td><td>0.0</td><td>2</td><td>1.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>39</td><td>0</td><td>1</td><td>138</td><td>220</td><td>0</td><td>0</td><td>152</td><td>0</td><td>0.0</td><td>2</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>57</td><td>1</td><td>1</td><td>154</td><td>232</td><td>0</td><td>2</td><td>164</td><td>0</td><td>0.0</td><td>1</td><td>1.0</td><td>3.0</td><td>1</td></tr>\n",
       "\t<tr><td>58</td><td>0</td><td>0</td><td>130</td><td>197</td><td>0</td><td>0</td><td>131</td><td>0</td><td>0.6</td><td>2</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>57</td><td>1</td><td>0</td><td>110</td><td>335</td><td>0</td><td>0</td><td>143</td><td>1</td><td>3.0</td><td>2</td><td>1.0</td><td>7.0</td><td>2</td></tr>\n",
       "\t<tr><td>47</td><td>1</td><td>1</td><td>130</td><td>253</td><td>0</td><td>0</td><td>179</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>55</td><td>0</td><td>0</td><td>128</td><td>205</td><td>0</td><td>1</td><td>130</td><td>1</td><td>2.0</td><td>2</td><td>1.0</td><td>7.0</td><td>3</td></tr>\n",
       "\t<tr><td>35</td><td>1</td><td>1</td><td>122</td><td>192</td><td>0</td><td>0</td><td>174</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>61</td><td>1</td><td>0</td><td>148</td><td>203</td><td>0</td><td>0</td><td>161</td><td>0</td><td>0.0</td><td>1</td><td>1.0</td><td>7.0</td><td>2</td></tr>\n",
       "\t<tr><td>58</td><td>1</td><td>0</td><td>114</td><td>318</td><td>0</td><td>1</td><td>140</td><td>0</td><td>4.4</td><td>3</td><td>3.0</td><td>6.0</td><td>4</td></tr>\n",
       "\t<tr><td>58</td><td>0</td><td>0</td><td>170</td><td>225</td><td>1</td><td>2</td><td>146</td><td>1</td><td>2.8</td><td>2</td><td>2.0</td><td>6.0</td><td>2</td></tr>\n",
       "\t<tr><td>56</td><td>1</td><td>1</td><td>130</td><td>221</td><td>0</td><td>2</td><td>163</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>7.0</td><td>0</td></tr>\n",
       "\t<tr><td>56</td><td>1</td><td>1</td><td>120</td><td>240</td><td>0</td><td>0</td><td>169</td><td>0</td><td>0.0</td><td>3</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>67</td><td>1</td><td>1</td><td>152</td><td>212</td><td>0</td><td>2</td><td>150</td><td>0</td><td>0.8</td><td>2</td><td>0.0</td><td>7.0</td><td>1</td></tr>\n",
       "\t<tr><td>55</td><td>0</td><td>1</td><td>132</td><td>342</td><td>0</td><td>0</td><td>166</td><td>0</td><td>1.2</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>44</td><td>1</td><td>0</td><td>120</td><td>169</td><td>0</td><td>0</td><td>144</td><td>1</td><td>2.8</td><td>3</td><td>0.0</td><td>6.0</td><td>2</td></tr>\n",
       "\t<tr><td>63</td><td>1</td><td>0</td><td>140</td><td>187</td><td>0</td><td>2</td><td>144</td><td>1</td><td>4.0</td><td>1</td><td>2.0</td><td>7.0</td><td>2</td></tr>\n",
       "\t<tr><td>63</td><td>0</td><td>0</td><td>124</td><td>197</td><td>0</td><td>0</td><td>136</td><td>1</td><td>0.0</td><td>2</td><td>0.0</td><td>3.0</td><td>1</td></tr>\n",
       "\t<tr><td>41</td><td>1</td><td>1</td><td>120</td><td>157</td><td>0</td><td>0</td><td>182</td><td>0</td><td>0.0</td><td>1</td><td>0.0</td><td>3.0</td><td>0</td></tr>\n",
       "\t<tr><td>59</td><td>1</td><td>0</td><td>164</td><td>176</td><td>1</td><td>2</td><td> 90</td><td>0</td><td>1.0</td><td>2</td><td>2.0</td><td>6.0</td><td>3</td></tr>\n",
       "\t<tr><td>57</td><td>0</td><td>0</td><td>140</td><td>241</td><td>0</td><td>0</td><td>123</td><td>1</td><td>0.2</td><td>2</td><td>0.0</td><td>7.0</td><td>1</td></tr>\n",
       "\t<tr><td>45</td><td>1</td><td>1</td><td>110</td><td>264</td><td>0</td><td>0</td><td>132</td><td>0</td><td>1.2</td><td>2</td><td>0.0</td><td>7.0</td><td>1</td></tr>\n",
       "\t<tr><td>68</td><td>1</td><td>0</td><td>144</td><td>193</td><td>1</td><td>0</td><td>141</td><td>0</td><td>3.4</td><td>2</td><td>2.0</td><td>7.0</td><td>2</td></tr>\n",
       "\t<tr><td>57</td><td>1</td><td>0</td><td>130</td><td>131</td><td>0</td><td>0</td><td>115</td><td>1</td><td>1.2</td><td>2</td><td>1.0</td><td>7.0</td><td>3</td></tr>\n",
       "\t<tr><td>57</td><td>0</td><td>1</td><td>130</td><td>236</td><td>0</td><td>2</td><td>174</td><td>0</td><td>0.0</td><td>2</td><td>1.0</td><td>3.0</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 299 × 14\n",
       "\\begin{tabular}{llllllllllllll}\n",
       " age & sex & cp & trestbps & chol & fbs & restecg & thalach & exang & oldpeak & slope & ca & thal & num\\\\\n",
       " <dbl> & <dbl> & <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 63 & 1 & 1 & 145 & 233 & 1 & 2 & 150 & 0 & 2.3 & 3 & 0.0 & 6.0 & 0\\\\\n",
       "\t 67 & 1 & 0 & 160 & 286 & 0 & 2 & 108 & 1 & 1.5 & 2 & 3.0 & 3.0 & 2\\\\\n",
       "\t 67 & 1 & 0 & 120 & 229 & 0 & 2 & 129 & 1 & 2.6 & 2 & 2.0 & 7.0 & 1\\\\\n",
       "\t 37 & 1 & 1 & 130 & 250 & 0 & 0 & 187 & 0 & 3.5 & 3 & 0.0 & 3.0 & 0\\\\\n",
       "\t 41 & 0 & 1 & 130 & 204 & 0 & 2 & 172 & 0 & 1.4 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 56 & 1 & 1 & 120 & 236 & 0 & 0 & 178 & 0 & 0.8 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 62 & 0 & 0 & 140 & 268 & 0 & 2 & 160 & 0 & 3.6 & 3 & 2.0 & 3.0 & 3\\\\\n",
       "\t 57 & 0 & 0 & 120 & 354 & 0 & 0 & 163 & 1 & 0.6 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 63 & 1 & 0 & 130 & 254 & 0 & 2 & 147 & 0 & 1.4 & 2 & 1.0 & 7.0 & 2\\\\\n",
       "\t 53 & 1 & 0 & 140 & 203 & 1 & 2 & 155 & 1 & 3.1 & 3 & 0.0 & 7.0 & 1\\\\\n",
       "\t 57 & 1 & 0 & 140 & 192 & 0 & 0 & 148 & 0 & 0.4 & 2 & 0.0 & 6.0 & 0\\\\\n",
       "\t 56 & 0 & 1 & 140 & 294 & 0 & 2 & 153 & 0 & 1.3 & 2 & 0.0 & 3.0 & 0\\\\\n",
       "\t 56 & 1 & 1 & 130 & 256 & 1 & 2 & 142 & 1 & 0.6 & 2 & 1.0 & 6.0 & 2\\\\\n",
       "\t 44 & 1 & 1 & 120 & 263 & 0 & 0 & 173 & 0 & 0.0 & 1 & 0.0 & 7.0 & 0\\\\\n",
       "\t 52 & 1 & 1 & 172 & 199 & 1 & 0 & 162 & 0 & 0.5 & 1 & 0.0 & 7.0 & 0\\\\\n",
       "\t 57 & 1 & 1 & 150 & 168 & 0 & 0 & 174 & 0 & 1.6 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 48 & 1 & 1 & 110 & 229 & 0 & 0 & 168 & 0 & 1.0 & 3 & 0.0 & 7.0 & 1\\\\\n",
       "\t 54 & 1 & 0 & 140 & 239 & 0 & 0 & 160 & 0 & 1.2 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 48 & 0 & 1 & 130 & 275 & 0 & 0 & 139 & 0 & 0.2 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 49 & 1 & 1 & 130 & 266 & 0 & 0 & 171 & 0 & 0.6 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 64 & 1 & 1 & 110 & 211 & 0 & 2 & 144 & 1 & 1.8 & 2 & 0.0 & 3.0 & 0\\\\\n",
       "\t 58 & 0 & 1 & 150 & 283 & 1 & 2 & 162 & 0 & 1.0 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 58 & 1 & 1 & 120 & 284 & 0 & 2 & 160 & 0 & 1.8 & 2 & 0.0 & 3.0 & 1\\\\\n",
       "\t 58 & 1 & 1 & 132 & 224 & 0 & 2 & 173 & 0 & 3.2 & 1 & 2.0 & 7.0 & 3\\\\\n",
       "\t 60 & 1 & 0 & 130 & 206 & 0 & 2 & 132 & 1 & 2.4 & 2 & 2.0 & 7.0 & 4\\\\\n",
       "\t 50 & 0 & 1 & 120 & 219 & 0 & 0 & 158 & 0 & 1.6 & 2 & 0.0 & 3.0 & 0\\\\\n",
       "\t 58 & 0 & 1 & 120 & 340 & 0 & 0 & 172 & 0 & 0.0 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 66 & 0 & 1 & 150 & 226 & 0 & 0 & 114 & 0 & 2.6 & 3 & 0.0 & 3.0 & 0\\\\\n",
       "\t 43 & 1 & 0 & 150 & 247 & 0 & 0 & 171 & 0 & 1.5 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 40 & 1 & 0 & 110 & 167 & 0 & 2 & 114 & 1 & 2.0 & 2 & 0.0 & 7.0 & 3\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t 66 & 1 & 0 & 160 & 228 & 0 & 2 & 138 & 0 & 2.3 & 1 & 0.0 & 6.0 & 0\\\\\n",
       "\t 46 & 1 & 0 & 140 & 311 & 0 & 0 & 120 & 1 & 1.8 & 2 & 2.0 & 7.0 & 2\\\\\n",
       "\t 71 & 0 & 0 & 112 & 149 & 0 & 0 & 125 & 0 & 1.6 & 2 & 0.0 & 3.0 & 0\\\\\n",
       "\t 59 & 1 & 1 & 134 & 204 & 0 & 0 & 162 & 0 & 0.8 & 1 & 2.0 & 3.0 & 1\\\\\n",
       "\t 64 & 1 & 1 & 170 & 227 & 0 & 2 & 155 & 0 & 0.6 & 2 & 0.0 & 7.0 & 0\\\\\n",
       "\t 66 & 0 & 1 & 146 & 278 & 0 & 2 & 152 & 0 & 0.0 & 2 & 1.0 & 3.0 & 0\\\\\n",
       "\t 39 & 0 & 1 & 138 & 220 & 0 & 0 & 152 & 0 & 0.0 & 2 & 0.0 & 3.0 & 0\\\\\n",
       "\t 57 & 1 & 1 & 154 & 232 & 0 & 2 & 164 & 0 & 0.0 & 1 & 1.0 & 3.0 & 1\\\\\n",
       "\t 58 & 0 & 0 & 130 & 197 & 0 & 0 & 131 & 0 & 0.6 & 2 & 0.0 & 3.0 & 0\\\\\n",
       "\t 57 & 1 & 0 & 110 & 335 & 0 & 0 & 143 & 1 & 3.0 & 2 & 1.0 & 7.0 & 2\\\\\n",
       "\t 47 & 1 & 1 & 130 & 253 & 0 & 0 & 179 & 0 & 0.0 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 55 & 0 & 0 & 128 & 205 & 0 & 1 & 130 & 1 & 2.0 & 2 & 1.0 & 7.0 & 3\\\\\n",
       "\t 35 & 1 & 1 & 122 & 192 & 0 & 0 & 174 & 0 & 0.0 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 61 & 1 & 0 & 148 & 203 & 0 & 0 & 161 & 0 & 0.0 & 1 & 1.0 & 7.0 & 2\\\\\n",
       "\t 58 & 1 & 0 & 114 & 318 & 0 & 1 & 140 & 0 & 4.4 & 3 & 3.0 & 6.0 & 4\\\\\n",
       "\t 58 & 0 & 0 & 170 & 225 & 1 & 2 & 146 & 1 & 2.8 & 2 & 2.0 & 6.0 & 2\\\\\n",
       "\t 56 & 1 & 1 & 130 & 221 & 0 & 2 & 163 & 0 & 0.0 & 1 & 0.0 & 7.0 & 0\\\\\n",
       "\t 56 & 1 & 1 & 120 & 240 & 0 & 0 & 169 & 0 & 0.0 & 3 & 0.0 & 3.0 & 0\\\\\n",
       "\t 67 & 1 & 1 & 152 & 212 & 0 & 2 & 150 & 0 & 0.8 & 2 & 0.0 & 7.0 & 1\\\\\n",
       "\t 55 & 0 & 1 & 132 & 342 & 0 & 0 & 166 & 0 & 1.2 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 44 & 1 & 0 & 120 & 169 & 0 & 0 & 144 & 1 & 2.8 & 3 & 0.0 & 6.0 & 2\\\\\n",
       "\t 63 & 1 & 0 & 140 & 187 & 0 & 2 & 144 & 1 & 4.0 & 1 & 2.0 & 7.0 & 2\\\\\n",
       "\t 63 & 0 & 0 & 124 & 197 & 0 & 0 & 136 & 1 & 0.0 & 2 & 0.0 & 3.0 & 1\\\\\n",
       "\t 41 & 1 & 1 & 120 & 157 & 0 & 0 & 182 & 0 & 0.0 & 1 & 0.0 & 3.0 & 0\\\\\n",
       "\t 59 & 1 & 0 & 164 & 176 & 1 & 2 &  90 & 0 & 1.0 & 2 & 2.0 & 6.0 & 3\\\\\n",
       "\t 57 & 0 & 0 & 140 & 241 & 0 & 0 & 123 & 1 & 0.2 & 2 & 0.0 & 7.0 & 1\\\\\n",
       "\t 45 & 1 & 1 & 110 & 264 & 0 & 0 & 132 & 0 & 1.2 & 2 & 0.0 & 7.0 & 1\\\\\n",
       "\t 68 & 1 & 0 & 144 & 193 & 1 & 0 & 141 & 0 & 3.4 & 2 & 2.0 & 7.0 & 2\\\\\n",
       "\t 57 & 1 & 0 & 130 & 131 & 0 & 0 & 115 & 1 & 1.2 & 2 & 1.0 & 7.0 & 3\\\\\n",
       "\t 57 & 0 & 1 & 130 & 236 & 0 & 2 & 174 & 0 & 0.0 & 2 & 1.0 & 3.0 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 299 × 14\n",
       "\n",
       "| age &lt;dbl&gt; | sex &lt;dbl&gt; | cp &lt;fct&gt; | trestbps &lt;dbl&gt; | chol &lt;dbl&gt; | fbs &lt;dbl&gt; | restecg &lt;dbl&gt; | thalach &lt;dbl&gt; | exang &lt;dbl&gt; | oldpeak &lt;dbl&gt; | slope &lt;dbl&gt; | ca &lt;chr&gt; | thal &lt;chr&gt; | num &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 63 | 1 | 1 | 145 | 233 | 1 | 2 | 150 | 0 | 2.3 | 3 | 0.0 | 6.0 | 0 |\n",
       "| 67 | 1 | 0 | 160 | 286 | 0 | 2 | 108 | 1 | 1.5 | 2 | 3.0 | 3.0 | 2 |\n",
       "| 67 | 1 | 0 | 120 | 229 | 0 | 2 | 129 | 1 | 2.6 | 2 | 2.0 | 7.0 | 1 |\n",
       "| 37 | 1 | 1 | 130 | 250 | 0 | 0 | 187 | 0 | 3.5 | 3 | 0.0 | 3.0 | 0 |\n",
       "| 41 | 0 | 1 | 130 | 204 | 0 | 2 | 172 | 0 | 1.4 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 56 | 1 | 1 | 120 | 236 | 0 | 0 | 178 | 0 | 0.8 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 62 | 0 | 0 | 140 | 268 | 0 | 2 | 160 | 0 | 3.6 | 3 | 2.0 | 3.0 | 3 |\n",
       "| 57 | 0 | 0 | 120 | 354 | 0 | 0 | 163 | 1 | 0.6 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 63 | 1 | 0 | 130 | 254 | 0 | 2 | 147 | 0 | 1.4 | 2 | 1.0 | 7.0 | 2 |\n",
       "| 53 | 1 | 0 | 140 | 203 | 1 | 2 | 155 | 1 | 3.1 | 3 | 0.0 | 7.0 | 1 |\n",
       "| 57 | 1 | 0 | 140 | 192 | 0 | 0 | 148 | 0 | 0.4 | 2 | 0.0 | 6.0 | 0 |\n",
       "| 56 | 0 | 1 | 140 | 294 | 0 | 2 | 153 | 0 | 1.3 | 2 | 0.0 | 3.0 | 0 |\n",
       "| 56 | 1 | 1 | 130 | 256 | 1 | 2 | 142 | 1 | 0.6 | 2 | 1.0 | 6.0 | 2 |\n",
       "| 44 | 1 | 1 | 120 | 263 | 0 | 0 | 173 | 0 | 0.0 | 1 | 0.0 | 7.0 | 0 |\n",
       "| 52 | 1 | 1 | 172 | 199 | 1 | 0 | 162 | 0 | 0.5 | 1 | 0.0 | 7.0 | 0 |\n",
       "| 57 | 1 | 1 | 150 | 168 | 0 | 0 | 174 | 0 | 1.6 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 48 | 1 | 1 | 110 | 229 | 0 | 0 | 168 | 0 | 1.0 | 3 | 0.0 | 7.0 | 1 |\n",
       "| 54 | 1 | 0 | 140 | 239 | 0 | 0 | 160 | 0 | 1.2 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 48 | 0 | 1 | 130 | 275 | 0 | 0 | 139 | 0 | 0.2 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 49 | 1 | 1 | 130 | 266 | 0 | 0 | 171 | 0 | 0.6 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 64 | 1 | 1 | 110 | 211 | 0 | 2 | 144 | 1 | 1.8 | 2 | 0.0 | 3.0 | 0 |\n",
       "| 58 | 0 | 1 | 150 | 283 | 1 | 2 | 162 | 0 | 1.0 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 58 | 1 | 1 | 120 | 284 | 0 | 2 | 160 | 0 | 1.8 | 2 | 0.0 | 3.0 | 1 |\n",
       "| 58 | 1 | 1 | 132 | 224 | 0 | 2 | 173 | 0 | 3.2 | 1 | 2.0 | 7.0 | 3 |\n",
       "| 60 | 1 | 0 | 130 | 206 | 0 | 2 | 132 | 1 | 2.4 | 2 | 2.0 | 7.0 | 4 |\n",
       "| 50 | 0 | 1 | 120 | 219 | 0 | 0 | 158 | 0 | 1.6 | 2 | 0.0 | 3.0 | 0 |\n",
       "| 58 | 0 | 1 | 120 | 340 | 0 | 0 | 172 | 0 | 0.0 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 66 | 0 | 1 | 150 | 226 | 0 | 0 | 114 | 0 | 2.6 | 3 | 0.0 | 3.0 | 0 |\n",
       "| 43 | 1 | 0 | 150 | 247 | 0 | 0 | 171 | 0 | 1.5 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 40 | 1 | 0 | 110 | 167 | 0 | 2 | 114 | 1 | 2.0 | 2 | 0.0 | 7.0 | 3 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 66 | 1 | 0 | 160 | 228 | 0 | 2 | 138 | 0 | 2.3 | 1 | 0.0 | 6.0 | 0 |\n",
       "| 46 | 1 | 0 | 140 | 311 | 0 | 0 | 120 | 1 | 1.8 | 2 | 2.0 | 7.0 | 2 |\n",
       "| 71 | 0 | 0 | 112 | 149 | 0 | 0 | 125 | 0 | 1.6 | 2 | 0.0 | 3.0 | 0 |\n",
       "| 59 | 1 | 1 | 134 | 204 | 0 | 0 | 162 | 0 | 0.8 | 1 | 2.0 | 3.0 | 1 |\n",
       "| 64 | 1 | 1 | 170 | 227 | 0 | 2 | 155 | 0 | 0.6 | 2 | 0.0 | 7.0 | 0 |\n",
       "| 66 | 0 | 1 | 146 | 278 | 0 | 2 | 152 | 0 | 0.0 | 2 | 1.0 | 3.0 | 0 |\n",
       "| 39 | 0 | 1 | 138 | 220 | 0 | 0 | 152 | 0 | 0.0 | 2 | 0.0 | 3.0 | 0 |\n",
       "| 57 | 1 | 1 | 154 | 232 | 0 | 2 | 164 | 0 | 0.0 | 1 | 1.0 | 3.0 | 1 |\n",
       "| 58 | 0 | 0 | 130 | 197 | 0 | 0 | 131 | 0 | 0.6 | 2 | 0.0 | 3.0 | 0 |\n",
       "| 57 | 1 | 0 | 110 | 335 | 0 | 0 | 143 | 1 | 3.0 | 2 | 1.0 | 7.0 | 2 |\n",
       "| 47 | 1 | 1 | 130 | 253 | 0 | 0 | 179 | 0 | 0.0 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 55 | 0 | 0 | 128 | 205 | 0 | 1 | 130 | 1 | 2.0 | 2 | 1.0 | 7.0 | 3 |\n",
       "| 35 | 1 | 1 | 122 | 192 | 0 | 0 | 174 | 0 | 0.0 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 61 | 1 | 0 | 148 | 203 | 0 | 0 | 161 | 0 | 0.0 | 1 | 1.0 | 7.0 | 2 |\n",
       "| 58 | 1 | 0 | 114 | 318 | 0 | 1 | 140 | 0 | 4.4 | 3 | 3.0 | 6.0 | 4 |\n",
       "| 58 | 0 | 0 | 170 | 225 | 1 | 2 | 146 | 1 | 2.8 | 2 | 2.0 | 6.0 | 2 |\n",
       "| 56 | 1 | 1 | 130 | 221 | 0 | 2 | 163 | 0 | 0.0 | 1 | 0.0 | 7.0 | 0 |\n",
       "| 56 | 1 | 1 | 120 | 240 | 0 | 0 | 169 | 0 | 0.0 | 3 | 0.0 | 3.0 | 0 |\n",
       "| 67 | 1 | 1 | 152 | 212 | 0 | 2 | 150 | 0 | 0.8 | 2 | 0.0 | 7.0 | 1 |\n",
       "| 55 | 0 | 1 | 132 | 342 | 0 | 0 | 166 | 0 | 1.2 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 44 | 1 | 0 | 120 | 169 | 0 | 0 | 144 | 1 | 2.8 | 3 | 0.0 | 6.0 | 2 |\n",
       "| 63 | 1 | 0 | 140 | 187 | 0 | 2 | 144 | 1 | 4.0 | 1 | 2.0 | 7.0 | 2 |\n",
       "| 63 | 0 | 0 | 124 | 197 | 0 | 0 | 136 | 1 | 0.0 | 2 | 0.0 | 3.0 | 1 |\n",
       "| 41 | 1 | 1 | 120 | 157 | 0 | 0 | 182 | 0 | 0.0 | 1 | 0.0 | 3.0 | 0 |\n",
       "| 59 | 1 | 0 | 164 | 176 | 1 | 2 |  90 | 0 | 1.0 | 2 | 2.0 | 6.0 | 3 |\n",
       "| 57 | 0 | 0 | 140 | 241 | 0 | 0 | 123 | 1 | 0.2 | 2 | 0.0 | 7.0 | 1 |\n",
       "| 45 | 1 | 1 | 110 | 264 | 0 | 0 | 132 | 0 | 1.2 | 2 | 0.0 | 7.0 | 1 |\n",
       "| 68 | 1 | 0 | 144 | 193 | 1 | 0 | 141 | 0 | 3.4 | 2 | 2.0 | 7.0 | 2 |\n",
       "| 57 | 1 | 0 | 130 | 131 | 0 | 0 | 115 | 1 | 1.2 | 2 | 1.0 | 7.0 | 3 |\n",
       "| 57 | 0 | 1 | 130 | 236 | 0 | 2 | 174 | 0 | 0.0 | 2 | 1.0 | 3.0 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "    age sex cp trestbps chol fbs restecg thalach exang oldpeak slope ca  thal\n",
       "1   63  1   1  145      233  1   2       150     0     2.3     3     0.0 6.0 \n",
       "2   67  1   0  160      286  0   2       108     1     1.5     2     3.0 3.0 \n",
       "3   67  1   0  120      229  0   2       129     1     2.6     2     2.0 7.0 \n",
       "4   37  1   1  130      250  0   0       187     0     3.5     3     0.0 3.0 \n",
       "5   41  0   1  130      204  0   2       172     0     1.4     1     0.0 3.0 \n",
       "6   56  1   1  120      236  0   0       178     0     0.8     1     0.0 3.0 \n",
       "7   62  0   0  140      268  0   2       160     0     3.6     3     2.0 3.0 \n",
       "8   57  0   0  120      354  0   0       163     1     0.6     1     0.0 3.0 \n",
       "9   63  1   0  130      254  0   2       147     0     1.4     2     1.0 7.0 \n",
       "10  53  1   0  140      203  1   2       155     1     3.1     3     0.0 7.0 \n",
       "11  57  1   0  140      192  0   0       148     0     0.4     2     0.0 6.0 \n",
       "12  56  0   1  140      294  0   2       153     0     1.3     2     0.0 3.0 \n",
       "13  56  1   1  130      256  1   2       142     1     0.6     2     1.0 6.0 \n",
       "14  44  1   1  120      263  0   0       173     0     0.0     1     0.0 7.0 \n",
       "15  52  1   1  172      199  1   0       162     0     0.5     1     0.0 7.0 \n",
       "16  57  1   1  150      168  0   0       174     0     1.6     1     0.0 3.0 \n",
       "17  48  1   1  110      229  0   0       168     0     1.0     3     0.0 7.0 \n",
       "18  54  1   0  140      239  0   0       160     0     1.2     1     0.0 3.0 \n",
       "19  48  0   1  130      275  0   0       139     0     0.2     1     0.0 3.0 \n",
       "20  49  1   1  130      266  0   0       171     0     0.6     1     0.0 3.0 \n",
       "21  64  1   1  110      211  0   2       144     1     1.8     2     0.0 3.0 \n",
       "22  58  0   1  150      283  1   2       162     0     1.0     1     0.0 3.0 \n",
       "23  58  1   1  120      284  0   2       160     0     1.8     2     0.0 3.0 \n",
       "24  58  1   1  132      224  0   2       173     0     3.2     1     2.0 7.0 \n",
       "25  60  1   0  130      206  0   2       132     1     2.4     2     2.0 7.0 \n",
       "26  50  0   1  120      219  0   0       158     0     1.6     2     0.0 3.0 \n",
       "27  58  0   1  120      340  0   0       172     0     0.0     1     0.0 3.0 \n",
       "28  66  0   1  150      226  0   0       114     0     2.6     3     0.0 3.0 \n",
       "29  43  1   0  150      247  0   0       171     0     1.5     1     0.0 3.0 \n",
       "30  40  1   0  110      167  0   2       114     1     2.0     2     0.0 7.0 \n",
       "⋮   ⋮   ⋮   ⋮  ⋮        ⋮    ⋮   ⋮       ⋮       ⋮     ⋮       ⋮     ⋮   ⋮   \n",
       "270 66  1   0  160      228  0   2       138     0     2.3     1     0.0 6.0 \n",
       "271 46  1   0  140      311  0   0       120     1     1.8     2     2.0 7.0 \n",
       "272 71  0   0  112      149  0   0       125     0     1.6     2     0.0 3.0 \n",
       "273 59  1   1  134      204  0   0       162     0     0.8     1     2.0 3.0 \n",
       "274 64  1   1  170      227  0   2       155     0     0.6     2     0.0 7.0 \n",
       "275 66  0   1  146      278  0   2       152     0     0.0     2     1.0 3.0 \n",
       "276 39  0   1  138      220  0   0       152     0     0.0     2     0.0 3.0 \n",
       "277 57  1   1  154      232  0   2       164     0     0.0     1     1.0 3.0 \n",
       "278 58  0   0  130      197  0   0       131     0     0.6     2     0.0 3.0 \n",
       "279 57  1   0  110      335  0   0       143     1     3.0     2     1.0 7.0 \n",
       "280 47  1   1  130      253  0   0       179     0     0.0     1     0.0 3.0 \n",
       "281 55  0   0  128      205  0   1       130     1     2.0     2     1.0 7.0 \n",
       "282 35  1   1  122      192  0   0       174     0     0.0     1     0.0 3.0 \n",
       "283 61  1   0  148      203  0   0       161     0     0.0     1     1.0 7.0 \n",
       "284 58  1   0  114      318  0   1       140     0     4.4     3     3.0 6.0 \n",
       "285 58  0   0  170      225  1   2       146     1     2.8     2     2.0 6.0 \n",
       "286 56  1   1  130      221  0   2       163     0     0.0     1     0.0 7.0 \n",
       "287 56  1   1  120      240  0   0       169     0     0.0     3     0.0 3.0 \n",
       "288 67  1   1  152      212  0   2       150     0     0.8     2     0.0 7.0 \n",
       "289 55  0   1  132      342  0   0       166     0     1.2     1     0.0 3.0 \n",
       "290 44  1   0  120      169  0   0       144     1     2.8     3     0.0 6.0 \n",
       "291 63  1   0  140      187  0   2       144     1     4.0     1     2.0 7.0 \n",
       "292 63  0   0  124      197  0   0       136     1     0.0     2     0.0 3.0 \n",
       "293 41  1   1  120      157  0   0       182     0     0.0     1     0.0 3.0 \n",
       "294 59  1   0  164      176  1   2        90     0     1.0     2     2.0 6.0 \n",
       "295 57  0   0  140      241  0   0       123     1     0.2     2     0.0 7.0 \n",
       "296 45  1   1  110      264  0   0       132     0     1.2     2     0.0 7.0 \n",
       "297 68  1   0  144      193  1   0       141     0     3.4     2     2.0 7.0 \n",
       "298 57  1   0  130      131  0   0       115     1     1.2     2     1.0 7.0 \n",
       "299 57  0   1  130      236  0   2       174     0     0.0     2     1.0 3.0 \n",
       "    num\n",
       "1   0  \n",
       "2   2  \n",
       "3   1  \n",
       "4   0  \n",
       "5   0  \n",
       "6   0  \n",
       "7   3  \n",
       "8   0  \n",
       "9   2  \n",
       "10  1  \n",
       "11  0  \n",
       "12  0  \n",
       "13  2  \n",
       "14  0  \n",
       "15  0  \n",
       "16  0  \n",
       "17  1  \n",
       "18  0  \n",
       "19  0  \n",
       "20  0  \n",
       "21  0  \n",
       "22  0  \n",
       "23  1  \n",
       "24  3  \n",
       "25  4  \n",
       "26  0  \n",
       "27  0  \n",
       "28  0  \n",
       "29  0  \n",
       "30  3  \n",
       "⋮   ⋮  \n",
       "270 0  \n",
       "271 2  \n",
       "272 0  \n",
       "273 1  \n",
       "274 0  \n",
       "275 0  \n",
       "276 0  \n",
       "277 1  \n",
       "278 0  \n",
       "279 2  \n",
       "280 0  \n",
       "281 3  \n",
       "282 0  \n",
       "283 2  \n",
       "284 4  \n",
       "285 2  \n",
       "286 0  \n",
       "287 0  \n",
       "288 1  \n",
       "289 0  \n",
       "290 2  \n",
       "291 2  \n",
       "292 1  \n",
       "293 0  \n",
       "294 3  \n",
       "295 1  \n",
       "296 1  \n",
       "297 2  \n",
       "298 3  \n",
       "299 1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "cd_mutate[cd_mutate == \"?\"] <- NA\n",
    "cd_mutate <- filter(cd_mutate, ca != \"NA\")\n",
    "cd_mutate <- mutate(cd_mutate, cp = ifelse((cp == 1| cp == 2 | cp ==3), 1, 0)) |>\n",
    "            mutate(cp = as_factor(cp)) \n",
    "cd_mutate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b3f483",
   "metadata": {},
   "source": [
    "For this model, we will be using the variables age, sex, chol, restecg, trestbps to predict the cp type. Hence, we should select these columns from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "837ce2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cd_select<-select(cd_mutate, age, chol, trestbps, cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9667ef6c",
   "metadata": {},
   "source": [
    "We have cleaned and wrangled the data to give a tidy data frame. We can now proceed to split the data into training and testing sets to conduct the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab65b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(88)\n",
    "cd_split<-initial_split(cd_select, prop=0.75, strata=cp)\n",
    "cd_training<-training(cd_split)\n",
    "cd_testing<-testing(cd_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2c61bf",
   "metadata": {},
   "source": [
    "Let's begin with choosing a K value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7578ead6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 49 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>neighbors</th><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>mean</th><th scope=col>n</th><th scope=col>std_err</th><th scope=col>.config</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 2</td><td>accuracy</td><td>binary</td><td>0.4811594</td><td>10</td><td>0.03699541</td><td>Preprocessor1_Model01</td></tr>\n",
       "\t<tr><td> 3</td><td>accuracy</td><td>binary</td><td>0.4668737</td><td>10</td><td>0.02320576</td><td>Preprocessor1_Model02</td></tr>\n",
       "\t<tr><td> 4</td><td>accuracy</td><td>binary</td><td>0.4668737</td><td>10</td><td>0.02320576</td><td>Preprocessor1_Model03</td></tr>\n",
       "\t<tr><td> 5</td><td>accuracy</td><td>binary</td><td>0.5124224</td><td>10</td><td>0.01846472</td><td>Preprocessor1_Model04</td></tr>\n",
       "\t<tr><td> 6</td><td>accuracy</td><td>binary</td><td>0.5124224</td><td>10</td><td>0.01846472</td><td>Preprocessor1_Model05</td></tr>\n",
       "\t<tr><td> 7</td><td>accuracy</td><td>binary</td><td>0.5623188</td><td>10</td><td>0.01646277</td><td>Preprocessor1_Model06</td></tr>\n",
       "\t<tr><td> 8</td><td>accuracy</td><td>binary</td><td>0.5623188</td><td>10</td><td>0.01646277</td><td>Preprocessor1_Model07</td></tr>\n",
       "\t<tr><td> 9</td><td>accuracy</td><td>binary</td><td>0.5801242</td><td>10</td><td>0.02220850</td><td>Preprocessor1_Model08</td></tr>\n",
       "\t<tr><td>10</td><td>accuracy</td><td>binary</td><td>0.5801242</td><td>10</td><td>0.02220850</td><td>Preprocessor1_Model09</td></tr>\n",
       "\t<tr><td>11</td><td>accuracy</td><td>binary</td><td>0.5722567</td><td>10</td><td>0.02364684</td><td>Preprocessor1_Model10</td></tr>\n",
       "\t<tr><td>12</td><td>accuracy</td><td>binary</td><td>0.5722567</td><td>10</td><td>0.02364684</td><td>Preprocessor1_Model11</td></tr>\n",
       "\t<tr><td>13</td><td>accuracy</td><td>binary</td><td>0.5587992</td><td>10</td><td>0.02370568</td><td>Preprocessor1_Model12</td></tr>\n",
       "\t<tr><td>14</td><td>accuracy</td><td>binary</td><td>0.5587992</td><td>10</td><td>0.02370568</td><td>Preprocessor1_Model13</td></tr>\n",
       "\t<tr><td>15</td><td>accuracy</td><td>binary</td><td>0.5587992</td><td>10</td><td>0.02940064</td><td>Preprocessor1_Model14</td></tr>\n",
       "\t<tr><td>16</td><td>accuracy</td><td>binary</td><td>0.5587992</td><td>10</td><td>0.02940064</td><td>Preprocessor1_Model15</td></tr>\n",
       "\t<tr><td>17</td><td>accuracy</td><td>binary</td><td>0.5397516</td><td>10</td><td>0.02331796</td><td>Preprocessor1_Model16</td></tr>\n",
       "\t<tr><td>18</td><td>accuracy</td><td>binary</td><td>0.5397516</td><td>10</td><td>0.02331796</td><td>Preprocessor1_Model17</td></tr>\n",
       "\t<tr><td>19</td><td>accuracy</td><td>binary</td><td>0.5349896</td><td>10</td><td>0.02500561</td><td>Preprocessor1_Model18</td></tr>\n",
       "\t<tr><td>20</td><td>accuracy</td><td>binary</td><td>0.5349896</td><td>10</td><td>0.02500561</td><td>Preprocessor1_Model19</td></tr>\n",
       "\t<tr><td>21</td><td>accuracy</td><td>binary</td><td>0.5132505</td><td>10</td><td>0.02799662</td><td>Preprocessor1_Model20</td></tr>\n",
       "\t<tr><td>22</td><td>accuracy</td><td>binary</td><td>0.5132505</td><td>10</td><td>0.02799662</td><td>Preprocessor1_Model21</td></tr>\n",
       "\t<tr><td>23</td><td>accuracy</td><td>binary</td><td>0.5354037</td><td>10</td><td>0.03201970</td><td>Preprocessor1_Model22</td></tr>\n",
       "\t<tr><td>24</td><td>accuracy</td><td>binary</td><td>0.5354037</td><td>10</td><td>0.03201970</td><td>Preprocessor1_Model23</td></tr>\n",
       "\t<tr><td>25</td><td>accuracy</td><td>binary</td><td>0.5571429</td><td>10</td><td>0.02756286</td><td>Preprocessor1_Model24</td></tr>\n",
       "\t<tr><td>26</td><td>accuracy</td><td>binary</td><td>0.5571429</td><td>10</td><td>0.02756286</td><td>Preprocessor1_Model25</td></tr>\n",
       "\t<tr><td>27</td><td>accuracy</td><td>binary</td><td>0.5440994</td><td>10</td><td>0.02793591</td><td>Preprocessor1_Model26</td></tr>\n",
       "\t<tr><td>28</td><td>accuracy</td><td>binary</td><td>0.5440994</td><td>10</td><td>0.02793591</td><td>Preprocessor1_Model27</td></tr>\n",
       "\t<tr><td>29</td><td>accuracy</td><td>binary</td><td>0.5571429</td><td>10</td><td>0.03335619</td><td>Preprocessor1_Model28</td></tr>\n",
       "\t<tr><td>30</td><td>accuracy</td><td>binary</td><td>0.5571429</td><td>10</td><td>0.03335619</td><td>Preprocessor1_Model29</td></tr>\n",
       "\t<tr><td>31</td><td>accuracy</td><td>binary</td><td>0.5527950</td><td>10</td><td>0.02385898</td><td>Preprocessor1_Model30</td></tr>\n",
       "\t<tr><td>32</td><td>accuracy</td><td>binary</td><td>0.5527950</td><td>10</td><td>0.02385898</td><td>Preprocessor1_Model31</td></tr>\n",
       "\t<tr><td>33</td><td>accuracy</td><td>binary</td><td>0.5836439</td><td>10</td><td>0.02811545</td><td>Preprocessor1_Model32</td></tr>\n",
       "\t<tr><td>34</td><td>accuracy</td><td>binary</td><td>0.5836439</td><td>10</td><td>0.02811545</td><td>Preprocessor1_Model33</td></tr>\n",
       "\t<tr><td>35</td><td>accuracy</td><td>binary</td><td>0.6057971</td><td>10</td><td>0.03261072</td><td>Preprocessor1_Model34</td></tr>\n",
       "\t<tr><td>36</td><td>accuracy</td><td>binary</td><td>0.6057971</td><td>10</td><td>0.03261072</td><td>Preprocessor1_Model35</td></tr>\n",
       "\t<tr><td>37</td><td>accuracy</td><td>binary</td><td>0.5931677</td><td>10</td><td>0.03629624</td><td>Preprocessor1_Model36</td></tr>\n",
       "\t<tr><td>38</td><td>accuracy</td><td>binary</td><td>0.5931677</td><td>10</td><td>0.03629624</td><td>Preprocessor1_Model37</td></tr>\n",
       "\t<tr><td>39</td><td>accuracy</td><td>binary</td><td>0.6240166</td><td>10</td><td>0.03516582</td><td>Preprocessor1_Model38</td></tr>\n",
       "\t<tr><td>40</td><td>accuracy</td><td>binary</td><td>0.6240166</td><td>10</td><td>0.03516582</td><td>Preprocessor1_Model39</td></tr>\n",
       "\t<tr><td>41</td><td>accuracy</td><td>binary</td><td>0.5884058</td><td>10</td><td>0.03493291</td><td>Preprocessor1_Model40</td></tr>\n",
       "\t<tr><td>42</td><td>accuracy</td><td>binary</td><td>0.5884058</td><td>10</td><td>0.03493291</td><td>Preprocessor1_Model41</td></tr>\n",
       "\t<tr><td>43</td><td>accuracy</td><td>binary</td><td>0.5701863</td><td>10</td><td>0.03979155</td><td>Preprocessor1_Model42</td></tr>\n",
       "\t<tr><td>44</td><td>accuracy</td><td>binary</td><td>0.5701863</td><td>10</td><td>0.03979155</td><td>Preprocessor1_Model43</td></tr>\n",
       "\t<tr><td>45</td><td>accuracy</td><td>binary</td><td>0.5706004</td><td>10</td><td>0.04392857</td><td>Preprocessor1_Model44</td></tr>\n",
       "\t<tr><td>46</td><td>accuracy</td><td>binary</td><td>0.5706004</td><td>10</td><td>0.04392857</td><td>Preprocessor1_Model45</td></tr>\n",
       "\t<tr><td>47</td><td>accuracy</td><td>binary</td><td>0.5527950</td><td>10</td><td>0.04412524</td><td>Preprocessor1_Model46</td></tr>\n",
       "\t<tr><td>48</td><td>accuracy</td><td>binary</td><td>0.5527950</td><td>10</td><td>0.04412524</td><td>Preprocessor1_Model47</td></tr>\n",
       "\t<tr><td>49</td><td>accuracy</td><td>binary</td><td>0.5484472</td><td>10</td><td>0.04022281</td><td>Preprocessor1_Model48</td></tr>\n",
       "\t<tr><td>50</td><td>accuracy</td><td>binary</td><td>0.5484472</td><td>10</td><td>0.04022281</td><td>Preprocessor1_Model49</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 49 × 7\n",
       "\\begin{tabular}{lllllll}\n",
       " neighbors & .metric & .estimator & mean & n & std\\_err & .config\\\\\n",
       " <dbl> & <chr> & <chr> & <dbl> & <int> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t  2 & accuracy & binary & 0.4811594 & 10 & 0.03699541 & Preprocessor1\\_Model01\\\\\n",
       "\t  3 & accuracy & binary & 0.4668737 & 10 & 0.02320576 & Preprocessor1\\_Model02\\\\\n",
       "\t  4 & accuracy & binary & 0.4668737 & 10 & 0.02320576 & Preprocessor1\\_Model03\\\\\n",
       "\t  5 & accuracy & binary & 0.5124224 & 10 & 0.01846472 & Preprocessor1\\_Model04\\\\\n",
       "\t  6 & accuracy & binary & 0.5124224 & 10 & 0.01846472 & Preprocessor1\\_Model05\\\\\n",
       "\t  7 & accuracy & binary & 0.5623188 & 10 & 0.01646277 & Preprocessor1\\_Model06\\\\\n",
       "\t  8 & accuracy & binary & 0.5623188 & 10 & 0.01646277 & Preprocessor1\\_Model07\\\\\n",
       "\t  9 & accuracy & binary & 0.5801242 & 10 & 0.02220850 & Preprocessor1\\_Model08\\\\\n",
       "\t 10 & accuracy & binary & 0.5801242 & 10 & 0.02220850 & Preprocessor1\\_Model09\\\\\n",
       "\t 11 & accuracy & binary & 0.5722567 & 10 & 0.02364684 & Preprocessor1\\_Model10\\\\\n",
       "\t 12 & accuracy & binary & 0.5722567 & 10 & 0.02364684 & Preprocessor1\\_Model11\\\\\n",
       "\t 13 & accuracy & binary & 0.5587992 & 10 & 0.02370568 & Preprocessor1\\_Model12\\\\\n",
       "\t 14 & accuracy & binary & 0.5587992 & 10 & 0.02370568 & Preprocessor1\\_Model13\\\\\n",
       "\t 15 & accuracy & binary & 0.5587992 & 10 & 0.02940064 & Preprocessor1\\_Model14\\\\\n",
       "\t 16 & accuracy & binary & 0.5587992 & 10 & 0.02940064 & Preprocessor1\\_Model15\\\\\n",
       "\t 17 & accuracy & binary & 0.5397516 & 10 & 0.02331796 & Preprocessor1\\_Model16\\\\\n",
       "\t 18 & accuracy & binary & 0.5397516 & 10 & 0.02331796 & Preprocessor1\\_Model17\\\\\n",
       "\t 19 & accuracy & binary & 0.5349896 & 10 & 0.02500561 & Preprocessor1\\_Model18\\\\\n",
       "\t 20 & accuracy & binary & 0.5349896 & 10 & 0.02500561 & Preprocessor1\\_Model19\\\\\n",
       "\t 21 & accuracy & binary & 0.5132505 & 10 & 0.02799662 & Preprocessor1\\_Model20\\\\\n",
       "\t 22 & accuracy & binary & 0.5132505 & 10 & 0.02799662 & Preprocessor1\\_Model21\\\\\n",
       "\t 23 & accuracy & binary & 0.5354037 & 10 & 0.03201970 & Preprocessor1\\_Model22\\\\\n",
       "\t 24 & accuracy & binary & 0.5354037 & 10 & 0.03201970 & Preprocessor1\\_Model23\\\\\n",
       "\t 25 & accuracy & binary & 0.5571429 & 10 & 0.02756286 & Preprocessor1\\_Model24\\\\\n",
       "\t 26 & accuracy & binary & 0.5571429 & 10 & 0.02756286 & Preprocessor1\\_Model25\\\\\n",
       "\t 27 & accuracy & binary & 0.5440994 & 10 & 0.02793591 & Preprocessor1\\_Model26\\\\\n",
       "\t 28 & accuracy & binary & 0.5440994 & 10 & 0.02793591 & Preprocessor1\\_Model27\\\\\n",
       "\t 29 & accuracy & binary & 0.5571429 & 10 & 0.03335619 & Preprocessor1\\_Model28\\\\\n",
       "\t 30 & accuracy & binary & 0.5571429 & 10 & 0.03335619 & Preprocessor1\\_Model29\\\\\n",
       "\t 31 & accuracy & binary & 0.5527950 & 10 & 0.02385898 & Preprocessor1\\_Model30\\\\\n",
       "\t 32 & accuracy & binary & 0.5527950 & 10 & 0.02385898 & Preprocessor1\\_Model31\\\\\n",
       "\t 33 & accuracy & binary & 0.5836439 & 10 & 0.02811545 & Preprocessor1\\_Model32\\\\\n",
       "\t 34 & accuracy & binary & 0.5836439 & 10 & 0.02811545 & Preprocessor1\\_Model33\\\\\n",
       "\t 35 & accuracy & binary & 0.6057971 & 10 & 0.03261072 & Preprocessor1\\_Model34\\\\\n",
       "\t 36 & accuracy & binary & 0.6057971 & 10 & 0.03261072 & Preprocessor1\\_Model35\\\\\n",
       "\t 37 & accuracy & binary & 0.5931677 & 10 & 0.03629624 & Preprocessor1\\_Model36\\\\\n",
       "\t 38 & accuracy & binary & 0.5931677 & 10 & 0.03629624 & Preprocessor1\\_Model37\\\\\n",
       "\t 39 & accuracy & binary & 0.6240166 & 10 & 0.03516582 & Preprocessor1\\_Model38\\\\\n",
       "\t 40 & accuracy & binary & 0.6240166 & 10 & 0.03516582 & Preprocessor1\\_Model39\\\\\n",
       "\t 41 & accuracy & binary & 0.5884058 & 10 & 0.03493291 & Preprocessor1\\_Model40\\\\\n",
       "\t 42 & accuracy & binary & 0.5884058 & 10 & 0.03493291 & Preprocessor1\\_Model41\\\\\n",
       "\t 43 & accuracy & binary & 0.5701863 & 10 & 0.03979155 & Preprocessor1\\_Model42\\\\\n",
       "\t 44 & accuracy & binary & 0.5701863 & 10 & 0.03979155 & Preprocessor1\\_Model43\\\\\n",
       "\t 45 & accuracy & binary & 0.5706004 & 10 & 0.04392857 & Preprocessor1\\_Model44\\\\\n",
       "\t 46 & accuracy & binary & 0.5706004 & 10 & 0.04392857 & Preprocessor1\\_Model45\\\\\n",
       "\t 47 & accuracy & binary & 0.5527950 & 10 & 0.04412524 & Preprocessor1\\_Model46\\\\\n",
       "\t 48 & accuracy & binary & 0.5527950 & 10 & 0.04412524 & Preprocessor1\\_Model47\\\\\n",
       "\t 49 & accuracy & binary & 0.5484472 & 10 & 0.04022281 & Preprocessor1\\_Model48\\\\\n",
       "\t 50 & accuracy & binary & 0.5484472 & 10 & 0.04022281 & Preprocessor1\\_Model49\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 49 × 7\n",
       "\n",
       "| neighbors &lt;dbl&gt; | .metric &lt;chr&gt; | .estimator &lt;chr&gt; | mean &lt;dbl&gt; | n &lt;int&gt; | std_err &lt;dbl&gt; | .config &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "|  2 | accuracy | binary | 0.4811594 | 10 | 0.03699541 | Preprocessor1_Model01 |\n",
       "|  3 | accuracy | binary | 0.4668737 | 10 | 0.02320576 | Preprocessor1_Model02 |\n",
       "|  4 | accuracy | binary | 0.4668737 | 10 | 0.02320576 | Preprocessor1_Model03 |\n",
       "|  5 | accuracy | binary | 0.5124224 | 10 | 0.01846472 | Preprocessor1_Model04 |\n",
       "|  6 | accuracy | binary | 0.5124224 | 10 | 0.01846472 | Preprocessor1_Model05 |\n",
       "|  7 | accuracy | binary | 0.5623188 | 10 | 0.01646277 | Preprocessor1_Model06 |\n",
       "|  8 | accuracy | binary | 0.5623188 | 10 | 0.01646277 | Preprocessor1_Model07 |\n",
       "|  9 | accuracy | binary | 0.5801242 | 10 | 0.02220850 | Preprocessor1_Model08 |\n",
       "| 10 | accuracy | binary | 0.5801242 | 10 | 0.02220850 | Preprocessor1_Model09 |\n",
       "| 11 | accuracy | binary | 0.5722567 | 10 | 0.02364684 | Preprocessor1_Model10 |\n",
       "| 12 | accuracy | binary | 0.5722567 | 10 | 0.02364684 | Preprocessor1_Model11 |\n",
       "| 13 | accuracy | binary | 0.5587992 | 10 | 0.02370568 | Preprocessor1_Model12 |\n",
       "| 14 | accuracy | binary | 0.5587992 | 10 | 0.02370568 | Preprocessor1_Model13 |\n",
       "| 15 | accuracy | binary | 0.5587992 | 10 | 0.02940064 | Preprocessor1_Model14 |\n",
       "| 16 | accuracy | binary | 0.5587992 | 10 | 0.02940064 | Preprocessor1_Model15 |\n",
       "| 17 | accuracy | binary | 0.5397516 | 10 | 0.02331796 | Preprocessor1_Model16 |\n",
       "| 18 | accuracy | binary | 0.5397516 | 10 | 0.02331796 | Preprocessor1_Model17 |\n",
       "| 19 | accuracy | binary | 0.5349896 | 10 | 0.02500561 | Preprocessor1_Model18 |\n",
       "| 20 | accuracy | binary | 0.5349896 | 10 | 0.02500561 | Preprocessor1_Model19 |\n",
       "| 21 | accuracy | binary | 0.5132505 | 10 | 0.02799662 | Preprocessor1_Model20 |\n",
       "| 22 | accuracy | binary | 0.5132505 | 10 | 0.02799662 | Preprocessor1_Model21 |\n",
       "| 23 | accuracy | binary | 0.5354037 | 10 | 0.03201970 | Preprocessor1_Model22 |\n",
       "| 24 | accuracy | binary | 0.5354037 | 10 | 0.03201970 | Preprocessor1_Model23 |\n",
       "| 25 | accuracy | binary | 0.5571429 | 10 | 0.02756286 | Preprocessor1_Model24 |\n",
       "| 26 | accuracy | binary | 0.5571429 | 10 | 0.02756286 | Preprocessor1_Model25 |\n",
       "| 27 | accuracy | binary | 0.5440994 | 10 | 0.02793591 | Preprocessor1_Model26 |\n",
       "| 28 | accuracy | binary | 0.5440994 | 10 | 0.02793591 | Preprocessor1_Model27 |\n",
       "| 29 | accuracy | binary | 0.5571429 | 10 | 0.03335619 | Preprocessor1_Model28 |\n",
       "| 30 | accuracy | binary | 0.5571429 | 10 | 0.03335619 | Preprocessor1_Model29 |\n",
       "| 31 | accuracy | binary | 0.5527950 | 10 | 0.02385898 | Preprocessor1_Model30 |\n",
       "| 32 | accuracy | binary | 0.5527950 | 10 | 0.02385898 | Preprocessor1_Model31 |\n",
       "| 33 | accuracy | binary | 0.5836439 | 10 | 0.02811545 | Preprocessor1_Model32 |\n",
       "| 34 | accuracy | binary | 0.5836439 | 10 | 0.02811545 | Preprocessor1_Model33 |\n",
       "| 35 | accuracy | binary | 0.6057971 | 10 | 0.03261072 | Preprocessor1_Model34 |\n",
       "| 36 | accuracy | binary | 0.6057971 | 10 | 0.03261072 | Preprocessor1_Model35 |\n",
       "| 37 | accuracy | binary | 0.5931677 | 10 | 0.03629624 | Preprocessor1_Model36 |\n",
       "| 38 | accuracy | binary | 0.5931677 | 10 | 0.03629624 | Preprocessor1_Model37 |\n",
       "| 39 | accuracy | binary | 0.6240166 | 10 | 0.03516582 | Preprocessor1_Model38 |\n",
       "| 40 | accuracy | binary | 0.6240166 | 10 | 0.03516582 | Preprocessor1_Model39 |\n",
       "| 41 | accuracy | binary | 0.5884058 | 10 | 0.03493291 | Preprocessor1_Model40 |\n",
       "| 42 | accuracy | binary | 0.5884058 | 10 | 0.03493291 | Preprocessor1_Model41 |\n",
       "| 43 | accuracy | binary | 0.5701863 | 10 | 0.03979155 | Preprocessor1_Model42 |\n",
       "| 44 | accuracy | binary | 0.5701863 | 10 | 0.03979155 | Preprocessor1_Model43 |\n",
       "| 45 | accuracy | binary | 0.5706004 | 10 | 0.04392857 | Preprocessor1_Model44 |\n",
       "| 46 | accuracy | binary | 0.5706004 | 10 | 0.04392857 | Preprocessor1_Model45 |\n",
       "| 47 | accuracy | binary | 0.5527950 | 10 | 0.04412524 | Preprocessor1_Model46 |\n",
       "| 48 | accuracy | binary | 0.5527950 | 10 | 0.04412524 | Preprocessor1_Model47 |\n",
       "| 49 | accuracy | binary | 0.5484472 | 10 | 0.04022281 | Preprocessor1_Model48 |\n",
       "| 50 | accuracy | binary | 0.5484472 | 10 | 0.04022281 | Preprocessor1_Model49 |\n",
       "\n"
      ],
      "text/plain": [
       "   neighbors .metric  .estimator mean      n  std_err    .config              \n",
       "1   2        accuracy binary     0.4811594 10 0.03699541 Preprocessor1_Model01\n",
       "2   3        accuracy binary     0.4668737 10 0.02320576 Preprocessor1_Model02\n",
       "3   4        accuracy binary     0.4668737 10 0.02320576 Preprocessor1_Model03\n",
       "4   5        accuracy binary     0.5124224 10 0.01846472 Preprocessor1_Model04\n",
       "5   6        accuracy binary     0.5124224 10 0.01846472 Preprocessor1_Model05\n",
       "6   7        accuracy binary     0.5623188 10 0.01646277 Preprocessor1_Model06\n",
       "7   8        accuracy binary     0.5623188 10 0.01646277 Preprocessor1_Model07\n",
       "8   9        accuracy binary     0.5801242 10 0.02220850 Preprocessor1_Model08\n",
       "9  10        accuracy binary     0.5801242 10 0.02220850 Preprocessor1_Model09\n",
       "10 11        accuracy binary     0.5722567 10 0.02364684 Preprocessor1_Model10\n",
       "11 12        accuracy binary     0.5722567 10 0.02364684 Preprocessor1_Model11\n",
       "12 13        accuracy binary     0.5587992 10 0.02370568 Preprocessor1_Model12\n",
       "13 14        accuracy binary     0.5587992 10 0.02370568 Preprocessor1_Model13\n",
       "14 15        accuracy binary     0.5587992 10 0.02940064 Preprocessor1_Model14\n",
       "15 16        accuracy binary     0.5587992 10 0.02940064 Preprocessor1_Model15\n",
       "16 17        accuracy binary     0.5397516 10 0.02331796 Preprocessor1_Model16\n",
       "17 18        accuracy binary     0.5397516 10 0.02331796 Preprocessor1_Model17\n",
       "18 19        accuracy binary     0.5349896 10 0.02500561 Preprocessor1_Model18\n",
       "19 20        accuracy binary     0.5349896 10 0.02500561 Preprocessor1_Model19\n",
       "20 21        accuracy binary     0.5132505 10 0.02799662 Preprocessor1_Model20\n",
       "21 22        accuracy binary     0.5132505 10 0.02799662 Preprocessor1_Model21\n",
       "22 23        accuracy binary     0.5354037 10 0.03201970 Preprocessor1_Model22\n",
       "23 24        accuracy binary     0.5354037 10 0.03201970 Preprocessor1_Model23\n",
       "24 25        accuracy binary     0.5571429 10 0.02756286 Preprocessor1_Model24\n",
       "25 26        accuracy binary     0.5571429 10 0.02756286 Preprocessor1_Model25\n",
       "26 27        accuracy binary     0.5440994 10 0.02793591 Preprocessor1_Model26\n",
       "27 28        accuracy binary     0.5440994 10 0.02793591 Preprocessor1_Model27\n",
       "28 29        accuracy binary     0.5571429 10 0.03335619 Preprocessor1_Model28\n",
       "29 30        accuracy binary     0.5571429 10 0.03335619 Preprocessor1_Model29\n",
       "30 31        accuracy binary     0.5527950 10 0.02385898 Preprocessor1_Model30\n",
       "31 32        accuracy binary     0.5527950 10 0.02385898 Preprocessor1_Model31\n",
       "32 33        accuracy binary     0.5836439 10 0.02811545 Preprocessor1_Model32\n",
       "33 34        accuracy binary     0.5836439 10 0.02811545 Preprocessor1_Model33\n",
       "34 35        accuracy binary     0.6057971 10 0.03261072 Preprocessor1_Model34\n",
       "35 36        accuracy binary     0.6057971 10 0.03261072 Preprocessor1_Model35\n",
       "36 37        accuracy binary     0.5931677 10 0.03629624 Preprocessor1_Model36\n",
       "37 38        accuracy binary     0.5931677 10 0.03629624 Preprocessor1_Model37\n",
       "38 39        accuracy binary     0.6240166 10 0.03516582 Preprocessor1_Model38\n",
       "39 40        accuracy binary     0.6240166 10 0.03516582 Preprocessor1_Model39\n",
       "40 41        accuracy binary     0.5884058 10 0.03493291 Preprocessor1_Model40\n",
       "41 42        accuracy binary     0.5884058 10 0.03493291 Preprocessor1_Model41\n",
       "42 43        accuracy binary     0.5701863 10 0.03979155 Preprocessor1_Model42\n",
       "43 44        accuracy binary     0.5701863 10 0.03979155 Preprocessor1_Model43\n",
       "44 45        accuracy binary     0.5706004 10 0.04392857 Preprocessor1_Model44\n",
       "45 46        accuracy binary     0.5706004 10 0.04392857 Preprocessor1_Model45\n",
       "46 47        accuracy binary     0.5527950 10 0.04412524 Preprocessor1_Model46\n",
       "47 48        accuracy binary     0.5527950 10 0.04412524 Preprocessor1_Model47\n",
       "48 49        accuracy binary     0.5484472 10 0.04022281 Preprocessor1_Model48\n",
       "49 50        accuracy binary     0.5484472 10 0.04022281 Preprocessor1_Model49"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“Removed 3 rows containing missing values (geom_point).”\n",
      "Warning message:\n",
      "“Removed 3 row(s) containing missing values (geom_path).”\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtAAAAJYCAMAAAB8aiEbAAADAFBMVEUAAAABAQECAgIDAwME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\nQKOICqBRRAXQKKICaBRRATSKqP4fpa3EX/a6NXUAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 300,
       "width": 360
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(88)\n",
    "options(repr.plot.height = 5, repr.plot.width = 6)\n",
    "\n",
    "cd_recipe <- recipe(cp ~ ., data = cd_training)|>\n",
    "            step_scale(all_predictors())|>\n",
    "            step_center(all_predictors()) \n",
    "           \n",
    "\n",
    "cd_vfold <- vfold_cv(cd_training, v = 10, strata = cp)\n",
    "\n",
    "knn_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "      set_engine(\"kknn\") |>\n",
    "      set_mode(\"classification\")\n",
    "\n",
    "k = tibble(neighbors = seq(2,50,1))\n",
    "\n",
    "knn_results <- workflow() |>\n",
    "      add_recipe(cd_recipe) |>\n",
    "      add_model(knn_tune) |>\n",
    "      tune_grid(resamples = cd_vfold, grid = k) |>\n",
    "      collect_metrics()\n",
    "\n",
    "accuracies <- knn_results |> \n",
    "      filter(.metric == \"accuracy\")\n",
    "\n",
    "accuracies\n",
    "cross_val_plot <- ggplot(accuracies, aes(x = neighbors, y = mean))+\n",
    "      geom_point() +\n",
    "      geom_line() +\n",
    "      labs(x = \"Neighbors\", y = \"Accuracy Estimate\") +\n",
    "      scale_x_continuous(breaks = seq(2, 50, by = 5)) +  # adjusting the x-axis\n",
    "      scale_y_continuous(limits = c(0.5, 1.0)) # adjusting the y-axis\n",
    "\n",
    "\n",
    "cross_val_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70e818b1-2df9-45f9-9232-535ce9be4020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 1 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>.estimate</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>accuracy</td><td>binary</td><td>0.5333333</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 3\n",
       "\\begin{tabular}{lll}\n",
       " .metric & .estimator & .estimate\\\\\n",
       " <chr> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t accuracy & binary & 0.5333333\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 3\n",
       "\n",
       "| .metric &lt;chr&gt; | .estimator &lt;chr&gt; | .estimate &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| accuracy | binary | 0.5333333 |\n",
       "\n"
      ],
      "text/plain": [
       "  .metric  .estimator .estimate\n",
       "1 accuracy binary     0.5333333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "          Truth\n",
       "Prediction  0  1\n",
       "         0 17 16\n",
       "         1 19 23"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(88)\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 39) |>\n",
    "  set_engine(\"kknn\") |>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "knn_fit <- workflow() |>\n",
    "  add_recipe(cd_recipe) |>\n",
    "  add_model(knn_spec) |>\n",
    "  fit(data = cd_training)\n",
    "\n",
    "cd_test_predictions <- predict(knn_fit, cd_testing) |>\n",
    "  bind_cols(cd_testing)\n",
    "\n",
    "cd_test_predictions |>\n",
    "  metrics(truth = cp, estimate = .pred_class) |>\n",
    "  filter(.metric == \"accuracy\")\n",
    "\n",
    "confusion <- cd_test_predictions |>\n",
    "             conf_mat(truth = cp, estimate = .pred_class)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76a8f77",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad26c03",
   "metadata": {},
   "source": [
    "Carson, J. (n.d.). 2019 ACC/AHA guideline on the primary prevention of ... - circulation. Retrieved April 8, \n",
    "2023, from https://www.ahajournals.org/doi/full/10.1161/CIR.0000000000000677\n",
    "\n",
    "Detrano, R., Janosi, A., Steinbrunn, W., Pfisterer, M., Schmid, J.-J., Sandhu, S., Guppy, K. H., \n",
    "Lee, S., & Froelicher, V. (1989). International application of a new probability algorithm \n",
    "for the diagnosis of coronary artery disease. The American Journal of Cardiology, 64(5), \n",
    "304–310. https://doi.org/10.1016/0002-9149(89)90524-9 \n",
    "\n",
    "Electrocardiogram. (n.d.). Retrieved April 8, 2023, from \n",
    "https://www.heartandstroke.ca/heart-disease/tests/electrocardiogram\n",
    "\n",
    "Rodgers, J., Jones, J., Bolleddu, S., Vanthenapalli, S., Rodgers, L., Shah, K., . . . Panguluri, S. (2019, \n",
    "April 27). Cardiovascular risks associated with gender and aging. Retrieved April 8, 2023, from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6616540/\n",
    "\n",
    "Wu, C., Hu, H., Chou, Y., Huang, N., Chou, Y., & Li, C. (2015, November). High blood pressure \n",
    "and all-cause and cardiovascular disease mortalities in community-dwelling older adults. Retrieved April 8, 2023, from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5059018/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
